{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmYEfR6mh5JJ"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 16891,
     "status": "ok",
     "timestamp": 1741055712836,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "KPdF0P3aSeKA"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/WA_Fn-UseC_-Telco-Customer-Churn.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m#DL Model\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#from tensorflow.keras.models import Sequential\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#from tensorflow.keras.optimizers import Adam\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#from scikeras.wrappers import KerasClassifier\u001b[39;00m\n\u001b[32m     26\u001b[39m file_path = \u001b[33m\"\u001b[39m\u001b[33m../data/WA_Fn-UseC_-Telco-Customer-Churn.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m df_original = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 원본 데이터 저장\u001b[39;00m\n\u001b[32m     28\u001b[39m df = df_original.copy()  \u001b[38;5;66;03m# 작업용 복사본 생성\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\github\\SKN10-2nd-5Team\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\github\\SKN10-2nd-5Team\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\github\\SKN10-2nd-5Team\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\github\\SKN10-2nd-5Team\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\github\\SKN10-2nd-5Team\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/WA_Fn-UseC_-Telco-Customer-Churn.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from sklearn.impute import SimpleImputer  #결측치 자동\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler  #scaling\n",
    "from imblearn.over_sampling import SMOTE #smote\n",
    "from sklearn.utils.class_weight import compute_class_weight #scaling- weight\n",
    "\n",
    "\n",
    "#DL Model\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "file_path = \"../data/Telco_customer.csv\"\n",
    "df_original = pd.read_csv(file_path)  # 원본 데이터 저장\n",
    "df = df_original.copy()  # 작업용 복사본 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vea6mTYMxY98"
   },
   "source": [
    "## random seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1741055718747,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "5IX915PSxa1F"
   },
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정 (데이터셋 준비 전에 실행)\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)  # ⬅ 데이터셋 준비 전에 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbIMonkLVPTa"
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1741055718763,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "frAP-v9ZpcGm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from utils import reset_seeds\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52230,
     "status": "ok",
     "timestamp": 1741055770995,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "3EcdHf-apTO9",
    "outputId": "ef5fad66-36e9-4dd5-f53a-d831cc59fbf1"
   },
   "outputs": [],
   "source": [
    "def __create_custom_features(df):\n",
    "    df = df.copy()  # 원본 데이터프레임 수정 방지\n",
    "\n",
    "    #  숫자로 변환 (오류 방지)\n",
    "    df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors='coerce')\n",
    "    df[\"tenure\"] = pd.to_numeric(df[\"tenure\"], errors='coerce')\n",
    "    df[\"MonthlyCharges\"] = pd.to_numeric(df[\"MonthlyCharges\"], errors='coerce')\n",
    "\n",
    "    #  NaN 값 처리\n",
    "    df[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(0)\n",
    "\n",
    "    # 신규 피처 생성\n",
    "    df.loc[(df[\"tenure\"] >= 0) & (df[\"tenure\"] <= 12), \"NEW_TENURE_YEAR\"] = \"0-1 Year\"\n",
    "    df.loc[(df[\"tenure\"] > 12) & (df[\"tenure\"] <= 24), \"NEW_TENURE_YEAR\"] = \"1-2 Year\"\n",
    "    df.loc[(df[\"tenure\"] > 24) & (df[\"tenure\"] <= 36), \"NEW_TENURE_YEAR\"] = \"2-3 Year\"\n",
    "    df.loc[(df[\"tenure\"] > 36) & (df[\"tenure\"] <= 48), \"NEW_TENURE_YEAR\"] = \"3-4 Year\"\n",
    "    df.loc[(df[\"tenure\"] > 48) & (df[\"tenure\"] <= 60), \"NEW_TENURE_YEAR\"] = \"4-5 Year\"\n",
    "    df.loc[(df[\"tenure\"] > 60) & (df[\"tenure\"] <= 72), \"NEW_TENURE_YEAR\"] = \"5-6 Year\"\n",
    "\n",
    "    #  Zero-Division 방지: tenure=0인 경우 1로 설정\n",
    "    df[\"tenure_fixed\"] = df[\"tenure\"].replace(0, 1)\n",
    "\n",
    "    #  연산 수행 가능하도록 수정 (무한대 발생 방지)\n",
    "    df[\"NEW_AVG_Charges\"] = df[\"TotalCharges\"] / df[\"tenure_fixed\"]\n",
    "\n",
    "    # MonthlyCharges가 0이면 1로 보정하여 Zero-Division 방지\n",
    "    df[\"MonthlyCharges_fixed\"] = df[\"MonthlyCharges\"].replace(0, 1)\n",
    "    df[\"NEW_Increase\"] = df[\"NEW_AVG_Charges\"] / df[\"MonthlyCharges_fixed\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "def __cleaning_data(df):\n",
    "    df = df.dropna()\n",
    "    num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges', 'NEW_AVG_Charges', 'NEW_Increase']\n",
    "\n",
    "    # 무한대 값 처리\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)  # inf를 NaN으로 변환\n",
    "    df.fillna(0, inplace=True)  # NaN 값 채우기\n",
    "\n",
    "    #  MinMaxScaler 적용\n",
    "    mms = MinMaxScaler()\n",
    "    df[num_cols] = mms.fit_transform(df[num_cols])\n",
    "\n",
    "    return df\n",
    "\n",
    "def __encode_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    #  Churn이 문자열이면 숫자로 변환\n",
    "    if 'Churn' in df.columns and df['Churn'].dtype == 'object':\n",
    "        df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "    #  범주형 변수 원-핫 인코딩\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def __smote_data(X, y):\n",
    "    sm = SMOTEENN(sampling_strategy=0.5)\n",
    "    X_smo, y_smo = sm.fit_resample(X, y)\n",
    "    return X_smo, y_smo\n",
    "\n",
    "#  1. 전처리 함수 실행\n",
    "df = __create_custom_features(df)\n",
    "df = __cleaning_data(df)\n",
    "df = __encode_data(df)\n",
    "\n",
    "# 2. Churn 컬럼 확인\n",
    "print(df.columns)  # \"Churn\"이 사라졌는지 확인\n",
    "\n",
    "#  3. X, y 분리\n",
    "if 'Churn' in df.columns:\n",
    "    X = df.drop(columns=['Churn']).values.astype(np.float32)\n",
    "    y = df['Churn'].values.astype(np.int64)\n",
    "else:\n",
    "    raise KeyError(\"Churn 컬럼이 데이터프레임에서 사라졌습니다. 전처리 과정을 다시 확인하세요.\")\n",
    "\n",
    "#  4. 불균형 데이터 처리\n",
    "X, y = __smote_data(X, y)\n",
    "\n",
    "#  이후 딥러닝 학습 코드 실행 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52086,
     "status": "ok",
     "timestamp": 1741055823078,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "xZsvXtdIuhBQ",
    "outputId": "078860dd-730b-459e-813b-840d3dcad8c2"
   },
   "outputs": [],
   "source": [
    "#  1. 전처리 함수 실행\n",
    "df = __create_custom_features(df)\n",
    "df = __cleaning_data(df)\n",
    "df = __encode_data(df)\n",
    "\n",
    "#  2. Churn 컬럼 확인\n",
    "print(df.dtypes)  # 데이터 타입 확인\n",
    "\n",
    "# 3. bool 타입 컬럼을 int로 변환 (이 문제 해결)\n",
    "df = df.astype({col: int for col in df.select_dtypes(include=['bool']).columns})\n",
    "\n",
    "#  4. X, y 분리\n",
    "if 'Churn' in df.columns:\n",
    "    X = df.drop(columns=['Churn']).values.astype(np.float32)  # 변환 오류 방지됨\n",
    "    y = df['Churn'].values.astype(np.int64)\n",
    "else:\n",
    "    raise KeyError(\"Churn 컬럼이 데이터프레임에서 사라졌습니다. 전처리 과정을 다시 확인하세요.\")\n",
    "\n",
    "# 5. 불균형 데이터 처리\n",
    "X, y = __smote_data(X, y)\n",
    "\n",
    "# 이후 딥러닝 학습 코드 실행 가능\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWblHBcz0ipu"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1741055823085,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "LvaGFzXcxwCv"
   },
   "outputs": [],
   "source": [
    "# 1. 모델 초기화\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 설정\n",
    "input_size = X.shape[1]  # X의 feature 개수\n",
    "output_size = len(set(y))  # 클래스 개수\n",
    "hidden_size = 32  # 은닉층 크기\n",
    "\n",
    "class MultiModel(nn.Module):\n",
    "    def __init__(self, input_size, out_size, hidden_size=32):\n",
    "        super().__init__()\n",
    "        self.lieanr_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size*2, out_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lieanr_stack(x)\n",
    "\n",
    "model = MultiModel(input_size, output_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1741055824218,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "CUIwJhmL7_kA"
   },
   "outputs": [],
   "source": [
    "#  2. 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#  3. 데이터셋을 훈련(train)과 검증(validation)으로 분할\n",
    "batch_size = 32\n",
    "dataset = TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long))\n",
    "train_size = int(0.8 * len(dataset))  # 80% 훈련 데이터\n",
    "val_size = len(dataset) - train_size  # 20% 검증 데이터\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "852g9u-08CFc"
   },
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741055824238,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "pgrIUAY18Q1p"
   },
   "outputs": [],
   "source": [
    "# 4. Early Stopping 클래스\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = np.inf\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True  #  조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvuGJqHx8MWI"
   },
   "source": [
    "## Traing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1741055824255,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "xKjsoKjB8Kba"
   },
   "outputs": [],
   "source": [
    "#  5. Training Loop (Validation Accuracy 기준으로 모델 저장)\n",
    "def train_loop(model, train_loader, val_loader, criterion, optimizer, epochs=20, device='cpu', patience=5):\n",
    "    model.train()\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_val_acc = 0.0  #  가장 높은 Validation Accuracy 저장\n",
    "    best_model_path = \"best_model.pth\"  #  최적 모델 저장 경로\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Progress\", leave=True):\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for batch_X, batch_y in train_loader :\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = correct / total * 100\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        train_acc_history.append(train_accuracy)\n",
    "\n",
    "        #  검증 데이터 평가 (Validation)\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # 정확도 계산\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == batch_y).sum().item()\n",
    "                total += batch_y.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = correct / total * 100\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "        val_acc_history.append(val_accuracy)\n",
    "\n",
    "        tqdm.write(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "        #  Validation Accuracy가 최고라면 모델 저장\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)  #  최적 모델 저장\n",
    "            print(f\" 모델 저장: Epoch {epoch+1}, Best Val Acc: {best_val_acc:.2f}%\")\n",
    "\n",
    "        #  Early Stopping 체크\n",
    "        early_stopping(avg_val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    return train_loss_history, val_loss_history, train_acc_history, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J53UYTY18bp0"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "executionInfo": {
     "elapsed": 10442,
     "status": "ok",
     "timestamp": 1741055834707,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "b04pnum68a7q",
    "outputId": "96e3e5eb-a8cb-4bbd-9384-0116f1eeb8b5"
   },
   "outputs": [],
   "source": [
    "#  7. Training 실행\n",
    "epochs = 50  # Early Stopping으로 조기 종료 가능\n",
    "train_loss, val_loss, train_acc, val_acc = train_loop(model, train_loader, val_loader, criterion, optimizer, epochs, device=device, patience=7)\n",
    "\n",
    "#  8. Loss 및 Accuracy 그래프 출력\n",
    "def plot_metrics(train_loss, val_loss, train_acc, val_acc):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    axs[0].plot(train_loss, label='Train Loss', linestyle=\"-\", marker=\"o\")\n",
    "    axs[0].plot(val_loss, label='Val Loss', linestyle=\"--\", marker=\"s\")\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].set_title('Train vs Validation Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    axs[1].plot(train_acc, label='Train Accuracy', linestyle=\"-\", marker=\"o\")\n",
    "    axs[1].plot(val_acc, label='Val Accuracy', linestyle=\"--\", marker=\"s\")\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Accuracy (%)')\n",
    "    axs[1].set_title('Train vs Validation Accuracy')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(train_loss, val_loss, train_acc, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1741055834744,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "KE9VpqsM8gCo",
    "outputId": "2928ae78-06a6-457a-d477-22c7f7aa4a52"
   },
   "outputs": [],
   "source": [
    "#  9. 최적 모델 불러와서 Test 평가\n",
    "def test_loop(model, X_test, y_test, criterion, device='cpu'):\n",
    "    best_model_path = \"best_model.pth\"\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        loss = criterion(outputs, y_test_tensor)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor) * 100\n",
    "\n",
    "    print(f\" 최적 Validation 모델을 사용한 Test Accuracy: {accuracy:.2f}%\")\n",
    "    return loss.item(), accuracy\n",
    "\n",
    "# Test Accuracy 확인\n",
    "test_loss, test_acc = test_loop(model, X, y, criterion, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1741055834775,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "jEa2wnV796B6",
    "outputId": "0e1e8907-9b1f-46f8-8fa7-7614a477a659"
   },
   "outputs": [],
   "source": [
    "# 9. 새로운 데이터 예측 함수\n",
    "def predict(model, X_new, device='cpu'):\n",
    "    best_model_path = \"best_model.pth\"\n",
    "\n",
    "    #  가중치만 로드하도록 변경 (보안 권장)\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    X_new_tensor = torch.tensor(X_new, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_new_tensor)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    return predictions.cpu().numpy()\n",
    "\n",
    "#  예측 예제\n",
    "X_new_sample = X[:100]\n",
    "predictions = predict(model, X_new_sample)\n",
    "print(\"예측 결과:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1741055834792,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "J5Ii_RAx-ky_",
    "outputId": "658f95cc-a712-4ce3-b2c3-0482e438f2f7"
   },
   "outputs": [],
   "source": [
    "def analyze_predictions(y_true, y_pred):\n",
    "    # DataFrame으로 정리하여 보기 쉽게 출력\n",
    "    df_results = pd.DataFrame({\n",
    "        'Actual': y_true,\n",
    "        'Predicted': y_pred,\n",
    "        'Correct': (y_true == y_pred)  # 맞으면 True, 틀리면 False\n",
    "    })\n",
    "\n",
    "    # 정확도 계산\n",
    "    accuracy = np.mean(df_results['Correct']) * 100  # 퍼센트 변환\n",
    "    correct_count = df_results['Correct'].sum()\n",
    "    total_count = len(df_results)\n",
    "\n",
    "    print(f\"\\n예측 정확도: {accuracy:.2f}% ({correct_count}/{total_count} 개 맞음)\")\n",
    "\n",
    "\n",
    "#  실제값과 예측값 비교 실행\n",
    "analyze_predictions(y[:100], predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 662,
     "status": "ok",
     "timestamp": 1741055835453,
     "user": {
      "displayName": "Seokhyeon Kwon",
      "userId": "02365031441986561291"
     },
     "user_tz": -540
    },
    "id": "Lv3ybkj224OM",
    "outputId": "f38ea89c-a0f9-4a8d-9264-3f1071caa81f"
   },
   "outputs": [],
   "source": [
    "#비선형데이터 파악\n",
    "\n",
    "\n",
    "# 주요 연속형 변수 선택\n",
    "numeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# 그래프 출력\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for i, feature in enumerate(numeric_features):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.scatterplot(x=df[feature], y=df['Churn'], alpha=0.5)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Churn')\n",
    "    plt.title(f\"{feature} vs Churn\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOgiJCvqeMrmVmleLF2XvKz",
   "provenance": [
    {
     "file_id": "14mi_zn4kAJGqNhS0-xWbNUTMWC-YMIOT",
     "timestamp": 1741049585113
    },
    {
     "file_id": "1WgnJ5Ax6AfcAhpCj2XPJWKfFSmZePtQ0",
     "timestamp": 1740967844678
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
